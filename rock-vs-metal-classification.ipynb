{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import set_option\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,KFold, cross_val_score,GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "% matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "data = pd.read_csv('Data/sonar.all-data.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape : (208, 61) \n",
      "\n",
      "Data Types :\n",
      "  0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8     float64\n",
      "9     float64\n",
      "10    float64\n",
      "11    float64\n",
      "12    float64\n",
      "13    float64\n",
      "14    float64\n",
      "15    float64\n",
      "16    float64\n",
      "17    float64\n",
      "18    float64\n",
      "19    float64\n",
      "20    float64\n",
      "21    float64\n",
      "22    float64\n",
      "23    float64\n",
      "24    float64\n",
      "25    float64\n",
      "26    float64\n",
      "27    float64\n",
      "28    float64\n",
      "29    float64\n",
      "       ...   \n",
      "31    float64\n",
      "32    float64\n",
      "33    float64\n",
      "34    float64\n",
      "35    float64\n",
      "36    float64\n",
      "37    float64\n",
      "38    float64\n",
      "39    float64\n",
      "40    float64\n",
      "41    float64\n",
      "42    float64\n",
      "43    float64\n",
      "44    float64\n",
      "45    float64\n",
      "46    float64\n",
      "47    float64\n",
      "48    float64\n",
      "49    float64\n",
      "50    float64\n",
      "51    float64\n",
      "52    float64\n",
      "53    float64\n",
      "54    float64\n",
      "55    float64\n",
      "56    float64\n",
      "57    float64\n",
      "58    float64\n",
      "59    float64\n",
      "60     object\n",
      "Length: 61, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Shape of the Data\n",
    "\n",
    "print('Data shape :', data.shape, '\\n')\n",
    "print('Data Types :\\n ', data.dtypes, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0      1      2      3      4      5      6      7      8      9  ...     51     52     53  \\\n",
      "0  0.020  0.037  0.043  0.021  0.095  0.099  0.154  0.160  0.311  0.211 ...  0.003  0.006  0.016   \n",
      "1  0.045  0.052  0.084  0.069  0.118  0.258  0.216  0.348  0.334  0.287 ...  0.008  0.009  0.005   \n",
      "2  0.026  0.058  0.110  0.108  0.097  0.228  0.243  0.377  0.560  0.619 ...  0.023  0.017  0.009   \n",
      "3  0.010  0.017  0.062  0.021  0.021  0.037  0.110  0.128  0.060  0.126 ...  0.012  0.004  0.015   \n",
      "4  0.076  0.067  0.048  0.039  0.059  0.065  0.121  0.247  0.356  0.446 ...  0.003  0.005  0.011   \n",
      "5  0.029  0.045  0.028  0.017  0.038  0.099  0.120  0.183  0.210  0.304 ...  0.004  0.001  0.004   \n",
      "6  0.032  0.096  0.132  0.141  0.167  0.171  0.073  0.140  0.208  0.351 ...  0.020  0.025  0.013   \n",
      "7  0.052  0.055  0.084  0.032  0.116  0.092  0.103  0.061  0.146  0.284 ...  0.008  0.012  0.004   \n",
      "8  0.022  0.037  0.048  0.048  0.065  0.059  0.075  0.010  0.068  0.149 ...  0.015  0.013  0.015   \n",
      "9  0.016  0.017  0.035  0.007  0.019  0.067  0.106  0.070  0.096  0.025 ...  0.009  0.022  0.018   \n",
      "\n",
      "      54     55     56     57     58     59  60  \n",
      "0  0.007  0.017  0.018  0.008  0.009  0.003   R  \n",
      "1  0.009  0.019  0.014  0.005  0.005  0.004   R  \n",
      "2  0.018  0.024  0.032  0.016  0.009  0.008   R  \n",
      "3  0.009  0.007  0.005  0.004  0.004  0.012   R  \n",
      "4  0.011  0.002  0.007  0.005  0.011  0.009   R  \n",
      "5  0.001  0.009  0.006  0.003  0.005  0.006   R  \n",
      "6  0.007  0.014  0.009  0.014  0.004  0.010   R  \n",
      "7  0.012  0.010  0.009  0.005  0.005  0.005   R  \n",
      "8  0.006  0.005  0.006  0.009  0.006  0.002   R  \n",
      "9  0.008  0.007  0.003  0.004  0.006  0.004   R  \n",
      "\n",
      "[10 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "# Peak at the data\n",
    "\n",
    "set_option('display.width', 100)\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Description : \n",
      "             0          1        2        3        4        5        6        7        8        9   \\\n",
      "count  208.000  2.080e+02  208.000  208.000  208.000  208.000  208.000  208.000  208.000  208.000   \n",
      "mean     0.029  3.844e-02    0.044    0.054    0.075    0.105    0.122    0.135    0.178    0.208   \n",
      "std      0.023  3.296e-02    0.038    0.047    0.056    0.059    0.062    0.085    0.118    0.134   \n",
      "min      0.002  6.000e-04    0.002    0.006    0.007    0.010    0.003    0.005    0.007    0.011   \n",
      "25%      0.013  1.645e-02    0.019    0.024    0.038    0.067    0.081    0.080    0.097    0.111   \n",
      "50%      0.023  3.080e-02    0.034    0.044    0.062    0.092    0.107    0.112    0.152    0.182   \n",
      "75%      0.036  4.795e-02    0.058    0.065    0.100    0.134    0.154    0.170    0.233    0.269   \n",
      "max      0.137  2.339e-01    0.306    0.426    0.401    0.382    0.373    0.459    0.683    0.711   \n",
      "\n",
      "         ...           50         51         52       53         54         55         56  \\\n",
      "count    ...      208.000  2.080e+02  2.080e+02  208.000  2.080e+02  2.080e+02  2.080e+02   \n",
      "mean     ...        0.016  1.342e-02  1.071e-02    0.011  9.290e-03  8.222e-03  7.820e-03   \n",
      "std      ...        0.012  9.634e-03  7.060e-03    0.007  7.088e-03  5.736e-03  5.785e-03   \n",
      "min      ...        0.000  8.000e-04  5.000e-04    0.001  6.000e-04  4.000e-04  3.000e-04   \n",
      "25%      ...        0.008  7.275e-03  5.075e-03    0.005  4.150e-03  4.400e-03  3.700e-03   \n",
      "50%      ...        0.014  1.140e-02  9.550e-03    0.009  7.500e-03  6.850e-03  5.950e-03   \n",
      "75%      ...        0.021  1.673e-02  1.490e-02    0.015  1.210e-02  1.058e-02  1.043e-02   \n",
      "max      ...        0.100  7.090e-02  3.900e-02    0.035  4.470e-02  3.940e-02  3.550e-02   \n",
      "\n",
      "              57         58         59  \n",
      "count  2.080e+02  2.080e+02  2.080e+02  \n",
      "mean   7.949e-03  7.941e-03  6.507e-03  \n",
      "std    6.470e-03  6.181e-03  5.031e-03  \n",
      "min    3.000e-04  1.000e-04  6.000e-04  \n",
      "25%    3.600e-03  3.675e-03  3.100e-03  \n",
      "50%    5.800e-03  6.400e-03  5.300e-03  \n",
      "75%    1.035e-02  1.033e-02  8.525e-03  \n",
      "max    4.400e-02  3.640e-02  4.390e-02  \n",
      "\n",
      "[8 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "# Description \n",
    "set_option('precision',3)\n",
    "print('Dataset Description : \\n', data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution in the dataset : \n",
      " 60\n",
      "M    111\n",
      "R     97\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Class Distribution\n",
    "\n",
    "print('Class Distribution in the dataset : \\n' ,data.groupby(60).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimodal Hist Visualization\n",
    "data.hist(sharex=False,sharey=False, xlabelsize=1, ylabelsize=1)\n",
    "plt.show()\n",
    "\n",
    "# Unimodal Density Visualization\n",
    "data.plot(kind='density', subplots=True, sharex=False, sharey=False, layout=(8,8) ,fontsize=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimodal Data Visulization\n",
    "\n",
    "# Plot correlation matrix\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(data.corr(), vmin=-1, vmax=1, interpolation=None)\n",
    "fig.colorbar(cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split Validation Dataset\n",
    "seed = 7\n",
    "X = data.iloc[:,0:60].values.astype(float)\n",
    "Y = data.iloc[:,60]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model using linear and non-linear machine learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non- Standardized Test Harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.782721 (0.093796)\n",
      "LDA: 0.746324 (0.117854)\n",
      "KNN: 0.808088 (0.067507)\n",
      "CART: 0.735662 (0.080437)\n",
      "NB: 0.648897 (0.141868)\n",
      "SVM: 0.608824 (0.118656)\n"
     ]
    }
   ],
   "source": [
    "# Create model test harness\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB',GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "# Evaluate data on test harness\n",
    "results = []\n",
    "names = []\n",
    "num_folds = 10\n",
    "scoring = 'accuracy' \n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.suptitle('Compare Algorithms')\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardized Test Harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledLR: 0.734191 (0.095885)\n",
      "ScaledLDA: 0.746324 (0.117854)\n",
      "ScaledKNN: 0.825735 (0.054511)\n",
      "ScaledCART: 0.747059 (0.096933)\n",
      "ScaledNB: 0.648897 (0.141868)\n",
      "ScaledSVM: 0.836397 (0.088697)\n"
     ]
    }
   ],
   "source": [
    "# Pipeline for standardized test harness\n",
    "\n",
    "pipelines=[]\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR', LogisticRegression())])))\n",
    "pipelines.append(('ScaledLDA', Pipeline([('Scaler', StandardScaler()), ('LDA', LinearDiscriminantAnalysis())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()), ('KNN', KNeighborsClassifier())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()), ('CART',  DecisionTreeClassifier())])))\n",
    "pipelines.append(('ScaledNB', Pipeline([('Scaler', StandardScaler()), ('NB', GaussianNB())])))\n",
    "pipelines.append(('ScaledSVM', Pipeline([('Scaler', StandardScaler()), ('SVM', SVC())])))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results  = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Scaled Algorithms\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.suptitle('Compare Algorithm Performance On Standardized Data ')\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning KNN and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.849398 using {'n_neighbors': 1}\n",
      "0.849398 (0.849398) with: {'n_neighbors': 1}\n",
      "0.837349 (0.837349) with: {'n_neighbors': 3}\n",
      "0.837349 (0.837349) with: {'n_neighbors': 5}\n",
      "0.765060 (0.765060) with: {'n_neighbors': 7}\n",
      "0.753012 (0.753012) with: {'n_neighbors': 9}\n",
      "0.734940 (0.734940) with: {'n_neighbors': 11}\n",
      "0.734940 (0.734940) with: {'n_neighbors': 13}\n",
      "0.728916 (0.728916) with: {'n_neighbors': 15}\n",
      "0.710843 (0.710843) with: {'n_neighbors': 17}\n",
      "0.722892 (0.722892) with: {'n_neighbors': 19}\n",
      "0.710843 (0.710843) with: {'n_neighbors': 21}\n"
     ]
    }
   ],
   "source": [
    "# Tuning scaled KNN\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "neighbors = [1,3,5,7,9,11,13,15,17,19,21]\n",
    "param_grid  = dict(n_neighbors=neighbors)\n",
    "model = KNeighborsClassifier()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, y_train)\n",
    "print('Best: %f using %s' % (grid_result.best_score_, grid_result.best_params_))\n",
    "mean = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['mean_test_score']\n",
    "params  = grid_result.cv_results_['params']\n",
    "for mean, stds, params in zip(mean, stds, params):\n",
    "    print('%f (%f) with: %r' % (mean, stds, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.867470 using {'C': 1.5, 'kernel': 'rbf'}\n",
      "0.759036 (0.098863) with: {'C': 0.1, 'kernel': 'linear'}\n",
      "0.530120 (0.118780) with: {'C': 0.1, 'kernel': 'poly'}\n",
      "0.572289 (0.130339) with: {'C': 0.1, 'kernel': 'rbf'}\n",
      "0.704819 (0.066360) with: {'C': 0.1, 'kernel': 'sigmoid'}\n",
      "0.746988 (0.108913) with: {'C': 0.3, 'kernel': 'linear'}\n",
      "0.644578 (0.132290) with: {'C': 0.3, 'kernel': 'poly'}\n",
      "0.765060 (0.092312) with: {'C': 0.3, 'kernel': 'rbf'}\n",
      "0.734940 (0.054631) with: {'C': 0.3, 'kernel': 'sigmoid'}\n",
      "0.740964 (0.083035) with: {'C': 0.5, 'kernel': 'linear'}\n",
      "0.680723 (0.098638) with: {'C': 0.5, 'kernel': 'poly'}\n",
      "0.789157 (0.064316) with: {'C': 0.5, 'kernel': 'rbf'}\n",
      "0.746988 (0.059265) with: {'C': 0.5, 'kernel': 'sigmoid'}\n",
      "0.746988 (0.084525) with: {'C': 0.7, 'kernel': 'linear'}\n",
      "0.740964 (0.127960) with: {'C': 0.7, 'kernel': 'poly'}\n",
      "0.813253 (0.084886) with: {'C': 0.7, 'kernel': 'rbf'}\n",
      "0.753012 (0.058513) with: {'C': 0.7, 'kernel': 'sigmoid'}\n",
      "0.759036 (0.096940) with: {'C': 0.9, 'kernel': 'linear'}\n",
      "0.771084 (0.102127) with: {'C': 0.9, 'kernel': 'poly'}\n",
      "0.837349 (0.087854) with: {'C': 0.9, 'kernel': 'rbf'}\n",
      "0.753012 (0.073751) with: {'C': 0.9, 'kernel': 'sigmoid'}\n",
      "0.753012 (0.099230) with: {'C': 1.0, 'kernel': 'linear'}\n",
      "0.789157 (0.107601) with: {'C': 1.0, 'kernel': 'poly'}\n",
      "0.837349 (0.087854) with: {'C': 1.0, 'kernel': 'rbf'}\n",
      "0.753012 (0.070213) with: {'C': 1.0, 'kernel': 'sigmoid'}\n",
      "0.771084 (0.106063) with: {'C': 1.3, 'kernel': 'linear'}\n",
      "0.819277 (0.106414) with: {'C': 1.3, 'kernel': 'poly'}\n",
      "0.849398 (0.079990) with: {'C': 1.3, 'kernel': 'rbf'}\n",
      "0.710843 (0.076865) with: {'C': 1.3, 'kernel': 'sigmoid'}\n",
      "0.759036 (0.091777) with: {'C': 1.5, 'kernel': 'linear'}\n",
      "0.831325 (0.109499) with: {'C': 1.5, 'kernel': 'poly'}\n",
      "0.867470 (0.090883) with: {'C': 1.5, 'kernel': 'rbf'}\n",
      "0.740964 (0.063717) with: {'C': 1.5, 'kernel': 'sigmoid'}\n",
      "0.746988 (0.090228) with: {'C': 1.7, 'kernel': 'linear'}\n",
      "0.831325 (0.115695) with: {'C': 1.7, 'kernel': 'poly'}\n",
      "0.861446 (0.087691) with: {'C': 1.7, 'kernel': 'rbf'}\n",
      "0.710843 (0.088140) with: {'C': 1.7, 'kernel': 'sigmoid'}\n",
      "0.759036 (0.094276) with: {'C': 2.0, 'kernel': 'linear'}\n",
      "0.831325 (0.108279) with: {'C': 2.0, 'kernel': 'poly'}\n",
      "0.867470 (0.094701) with: {'C': 2.0, 'kernel': 'rbf'}\n",
      "0.728916 (0.095050) with: {'C': 2.0, 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "# Tuning SVM\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "c_values = [0.1,0.3,0.5,0.7,0.9,1.0,1.3,1.5,1.7,2.0]\n",
    "kernel_values = ['linear', 'poly','rbf','sigmoid']\n",
    "param_grid = dict(C=c_values, kernel=kernel_values)\n",
    "model = SVC()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result  = grid.fit(rescaledX, y_train)\n",
    "print('Best: %f using %s' % (grid_result.best_score_, grid_result.best_params_))\n",
    "mean = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, std, param in zip(mean, stds, params):\n",
    "    print('%f (%f) with: %r' % (mean, std, param))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Using Ensemble Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledAB: 0.813971 (0.066017)\n",
      "ScaledGBM: 0.847794 (0.106873)\n",
      "ScaledRF: 0.783456 (0.046633)\n",
      "ScaledET: 0.811029 (0.166891)\n"
     ]
    }
   ],
   "source": [
    "# ensemble scaled algorithms\n",
    "\n",
    "ensemble = []\n",
    "ensemble.append(('ScaledAB', Pipeline([('Scaler', StandardScaler()), ('AB', AdaBoostClassifier())])))\n",
    "ensemble.append(('ScaledGBM', Pipeline([('Scaler', StandardScaler()), ('GBM', GradientBoostingClassifier())])))\n",
    "ensemble.append(('ScaledRF', Pipeline([('Scaler', StandardScaler()), ('RF', RandomForestClassifier())])))\n",
    "ensemble.append(('ScaledET', Pipeline([('Scaler', StandardScaler()), ('ET', ExtraTreesClassifier())])))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in ensemble:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('%s: %f (%f)'  % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare algorithhms \n",
    "fig  = plt.figure()\n",
    "fig.suptitle('Compare Algorithms')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Classification Using Final model (SVC) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  85.71428571428571 \n",
      "\n",
      "Confusion Matrix : \n",
      " [[23  4]\n",
      " [ 2 13]] \n",
      "\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          M       0.92      0.85      0.88        27\n",
      "          R       0.76      0.87      0.81        15\n",
      "\n",
      "avg / total       0.86      0.86      0.86        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GBM model classification\n",
    "\n",
    "scaler  = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "model = SVC(C=1.5, kernel='rbf')\n",
    "model.fit(rescaledX, y_train)\n",
    "\n",
    "# test the algorithm on validation dataset\n",
    "rescaled_vali_X = scaler.transform(X_test)\n",
    "preditions = model.predict(rescaled_vali_X)\n",
    "print('Accuracy: ', accuracy_score(y_test, preditions) * 100, '\\n')\n",
    "print('Confusion Matrix : \\n',confusion_matrix(y_test, preditions), '\\n')\n",
    "print('Classification Report : \\n ',classification_report(y_test, preditions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
